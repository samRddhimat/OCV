{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1304a23-f66e-4bd6-8569-26083cddcab2",
   "metadata": {},
   "source": [
    "## <code style=\"background:red;color:white\">Image Enhancement</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e98d64-45bb-499d-97a3-435c6711b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as mplt\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eef1a4-586a-4733-a1ec-3df4e9618dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread(\"D:/Repository/OCV/04_image_enhancement/04_New_Zealand_Coast.jpg\",cv2.IMREAD_COLOR)\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "Image(filename=\"D:/Repository/OCV/04_image_enhancement/04_New_Zealand_Coast.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fde9c-81c4-473f-a49d-964c8643bc15",
   "metadata": {},
   "source": [
    "## <code style=\"background:red;color:white\">Addition or Brightness</code>\n",
    "\n",
    "Simple addition of images. This results in increasing or decreasing the brightness of the image since we are eventually increasing or decreasing the intensity values of each pixel by the same amount. So, this will result in a global increase/decrease in brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02a9e0-a1ac-4644-b97d-45263c035c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.ones(img_rgb.shape,dtype=\"uint8\") * 50\n",
    "\n",
    "img_rgb_brighter = cv2.add(img_rgb, matrix)\n",
    "img_rgb_darker = cv2.subtract(img_rgb,matrix)\n",
    "\n",
    "# img_rgb_darker_2 =cv2.subtract(img_rgb,img_rgb_darker)\n",
    "fig,axs = mplt.subplots(1,3,figsize=(18,5))\n",
    "\n",
    "axs[0].set_title(\"Darker\")\n",
    "axs[0].imshow(img_rgb_darker)\n",
    "axs[0].title.set_size(10)\n",
    "\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[1].imshow(img_rgb)\n",
    "axs[1].title.set_size(10)\n",
    "\n",
    "axs[2].set_title(\"Brighter\")\n",
    "axs[2].imshow(img_rgb_brighter)\n",
    "axs[2].title.set_size(10)\n",
    "\n",
    "mplt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2aa9c-c95d-40a8-98bb-9cd4338d1487",
   "metadata": {},
   "source": [
    "## <code style=\"background:red;color:white\">Multiplication or Contrast</code>\n",
    "\n",
    "Just like addition can result in brightness change, multiplication can be used to improve the contrast of the image.\n",
    "\n",
    "Contrast is the difference in the intensity values of the pixels of an image. Multiplying the intensity values with a constant can make the difference larger or smaller ( if multiplying factor is < 1 ).\n",
    "\n",
    "NB: Contrast defined as difference in intensity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028e0d4-0810-4f34-ab37-afac165639bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.ones(img_rgb.shape) * 0.8\n",
    "matrix2 = np.ones(img_rgb.shape) * 1.2\n",
    "\n",
    "img_rgb_darker = np.uint8(cv2.multiply(np.float64(img_rgb), matrix1))\n",
    "img_rgb_brighter = np.uint8(cv2.multiply(np.float64(img_rgb), matrix2))\n",
    "\n",
    "fig,axs = mplt.subplots(1,3,figsize=(18,5))\n",
    "axs[0].set_title(\"Lower Contrast\")\n",
    "axs[0].imshow(img_rgb_darker)\n",
    "axs[0].title.set_size(10)\n",
    "\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[1].imshow(img_rgb)\n",
    "axs[1].title.set_size(10)\n",
    "\n",
    "cv2.circle(img_rgb_brighter, (110,70), 80, (255, 255, 55), thickness=5, lineType=cv2.LINE_AA);\n",
    "\n",
    "cv2.circle(img_rgb_brighter, (210,300), 80, (255, 0, 250), thickness=5, lineType=cv2.LINE_AA);\n",
    "cv2.arrowedLine(img_rgb_brighter, (210,300), (210,300), (255, 0, 250), thickness=5, line_type=8);\n",
    "\n",
    "axs[2].set_title(\"Higher Contrast\")\n",
    "axs[2].imshow(img_rgb_brighter)\n",
    "axs[2].title.set_size(10)\n",
    "\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b3c83-4a44-49f8-8418-da8ff8d7e9c5",
   "metadata": {},
   "source": [
    "### <code style=\"background:green;color:white\">Weird colors</code>\n",
    "\n",
    "What happened?\n",
    "Can you see the weird colors in some areas of the image after multiplication?\n",
    "\n",
    "The issue is that after multiplying, the values which are already high, are becoming greater than 255. Thus, the overflow issue. How do we overcome this?\n",
    "\n",
    "## <code style=\"background:red;color:white\">Handling overflow using np.clip</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36159b69-9343-4ec3-b4b5-053fe18c6c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.ones(img_rgb.shape) * 0.8\n",
    "matrix2 = np.ones(img_rgb.shape) * 1.2\n",
    "\n",
    "img_rgb_lower = np.uint8(cv2.multiply(np.float64(img_rgb), matrix1))\n",
    "img_rgb_higher = np.uint8(np.clip(cv2.multiply(np.float64(img_rgb), matrix2),0,255))\n",
    "\n",
    "fig,axs = mplt.subplots(1,3,figsize=(18,5))\n",
    "axs[0].set_title(\"Lower Contrast\")\n",
    "axs[0].imshow(img_rgb_darker)\n",
    "axs[0].title.set_size(10)\n",
    "\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[1].imshow(img_rgb)\n",
    "axs[1].title.set_size(10)\n",
    "\n",
    "axs[2].set_title(\"Higher Contrast\")\n",
    "axs[2].imshow(img_rgb_higher)\n",
    "axs[2].title.set_size(10)\n",
    "\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49660ba4-df32-4b7a-81b2-d948e8f1ecf9",
   "metadata": {},
   "source": [
    "## <code style=\"background:red;color:white\">Image Thresholding</code>\n",
    "\n",
    "Binary Images have a lot of use cases in Image Processing. One of the most common use cases is that of creating masks. Image Masks allow us to process on specific parts of an image keeping the other parts intact. Image Thresholding is used to create Binary Images from grayscale images. You can use different thresholds to create different binary images from the same original image.\n",
    "\n",
    "#### <code style=\"background:red;color:white\">Function Syntax</code>\n",
    "\n",
    "<b>retval, dst = cv2.threshold( src, thresh, maxval, type[, dst] )</b>\n",
    "<ol><li><b>dst:</b> The output array of the same size and type and the same number of channels as <b>src</b>.</li></ol>\n",
    "\n",
    "The function has 4 required arguments:\n",
    "<ol type=\"1\">\n",
    "<li>src: input array (multiple-channel, 8-bit or 32-bit floating point).</li>\n",
    "\n",
    "<li>thresh: threshold value.</li>\n",
    "\n",
    "<li>maxval: maximum value to use with the THRESH_BINARY and THRESH_BINARY_INV thresholding types.</li>\n",
    "\n",
    "<li>type: thresholding type (see ThresholdTypes).\n",
    "</li></ol>\n",
    "\n",
    "\n",
    "#### <code style=\"background:red;color:white\">Function Syntax</code>\n",
    "<b>dst = cv.adaptiveThreshold( src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst] )</b>\n",
    "dst Destination image of the same size and the same type as src.\n",
    "\n",
    "The function has 6 required arguments:\n",
    "\n",
    "<ol type=\"1\">\n",
    "<li>src: Source 8-bit single-channel image.</li>\n",
    "\n",
    "<li>maxValue: Non-zero value assigned to the pixels for which the condition is satisfied</li>\n",
    "\n",
    "<li>adaptiveMethod: Adaptive thresholding algorithm to use, see AdaptiveThresholdTypes. The BORDER_REPLICATE | BORDER_ISOLATED is used to process boundaries.</li>\n",
    "\n",
    "<li>thresholdType: Thresholding type that must be either THRESH_BINARY or THRESH_BINARY_INV, see ThresholdTypes.</li>\n",
    "\n",
    "<li>blockSize: Size of a pixel neighborhood that is used to calculate a threshold value for the pixel: 3, 5, 7, and so on.</li>\n",
    "\n",
    "<li>C: Constant subtracted from the mean or weighted mean (see the details below). Normally, it is positive but may be zero or negative as well.</li>\n",
    "\n",
    "</ol>\n",
    "<a href=\"https://docs.opencv.org/4.5.1/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57\">Documentation link</a> <br>\n",
    "<a href=\"https://docs.opencv.org/4.5.1/d7/d4d/tutorial_py_thresholding.html\">Documentation link</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc052b-f774-4972-a935-e1f59e3d2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_read = cv2.imread(\"D:/Repository/OCV/04_image_enhancement/04_building-windows.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# print(img_read )\n",
    "retval, img_thresh = cv2.threshold(img_read, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# mplt.subplot(122);mplt.imshow(img_thresh, cmap=\"gray\");mplt.title(\"Thresholded\")\n",
    "\n",
    "fig,axs = mplt.subplots(1,2,figsize=(18,5))\n",
    "\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(img_read, cmap=\"gray\")\n",
    "axs[0].title.set_size(10)\n",
    "\n",
    "axs[1].set_title(\"Original\")\n",
    "axs[1].imshow(img_thresh,cmap=\"gray\")\n",
    "axs[1].title.set_size(10)\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc71a24-2aa7-4957-b943-571760456404",
   "metadata": {},
   "source": [
    "## <code style=\"background:red;color:white\">Application: Sheet Music Reader</code>\n",
    "\n",
    "\n",
    "<pre>Suppose you wanted to build an application that could read (decode) sheet music. This is similar to Optical Character Recognigition (OCR) for text documents where the goal is to recognize text characters. In either application, one of the first steps in the processing pipeline is to isolate the important information in the image of a document (separating it from the background). This task can be accomplished with thresholding techniques. Let's take a look at an example.</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919b152-74de-4a59-85f7-9fb9f4ae1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_read = cv2.imread(\"D:/Repository/OCV/04_image_enhancement/04_Piano_Sheet_Music.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Perform global thresholding\n",
    "retval, img_thresh_gbl_1 = cv2.threshold(img_read, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Perform global thresholding\n",
    "retval, img_thresh_gbl_2 = cv2.threshold(img_read, 130, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Perform adaptive thresholding\n",
    "img_thresh_adp = cv2.adaptiveThreshold(img_read, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 7)\n",
    "\n",
    "fig,axs = mplt.subplots(1,4,figsize=(18,5))\n",
    "\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].imshow(img_read,cmap=\"gray\")\n",
    "axs[0].title.set_size(10)\n",
    "\n",
    "axs[1].set_title(\"Thresholded (global: 50)\")\n",
    "axs[1].imshow(img_thresh_gbl_1,cmap=\"gray\")\n",
    "axs[1].title.set_size(10)\n",
    "\n",
    "axs[2].set_title(\"Thresholded (global: 130)\")\n",
    "axs[2].imshow(img_thresh_gbl_2,cmap=\"gray\")\n",
    "axs[2].title.set_size(10)\n",
    "\n",
    "axs[3].set_title(\"Thresholded (adaptive)\")\n",
    "axs[3].imshow(img_thresh_adp,cmap=\"gray\")\n",
    "axs[3].title.set_size(10)\n",
    "\n",
    "mplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb848b-a750-4313-892d-aa76e45d8f28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
